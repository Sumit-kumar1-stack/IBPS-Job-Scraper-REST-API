# ğŸ¦ IBPS Job Scraper & REST API

This project is a **Django REST Framework (DRF)** based web application that scrapes **latest job notifications from the IBPS (Institute of Banking Personnel Selection)** official website and provides them through a secure **REST API**.  
It is designed to automate the process of fetching, storing, and serving job data, which can later be used by mobile apps, dashboards, or other job-related platforms.

---

## ğŸ” Project Overview

The main idea of this project is to:
1. **Scrape job listings** (title, link, and publish date) from the official IBPS website.  
2. **Store those listings in a database** using Django ORM.  
3. **Expose the job data through REST API endpoints** for authenticated users.

This ensures that every time IBPS updates new recruitment notifications, the scraper can fetch them and update the backend automatically.

---

## âš™ï¸ Tech Stack Used

- **Python** â€“ core programming language  
- **Django** â€“ web framework  
- **Django REST Framework (DRF)** â€“ for building APIs  
- **SQLite** â€“ lightweight database  
- **BeautifulSoup (bs4)** â€“ for web scraping HTML content  
- **Requests** â€“ for making HTTP requests  
- **Token Authentication** â€“ for secure API access  

---

## ğŸš€ Features

âœ… Scrapes job data (title, link, date) directly from IBPS official site  
âœ… Automatically stores scraped jobs into a database  
âœ… REST API endpoint (`/api/jobs/`) to fetch job listings  
âœ… Token-based authentication for API access  
âœ… Easy to extend â€” can be customized to scrape other websites too  
âœ… Clean, modular, and production-ready Django setup  

---

## ğŸ§© Project Structure

ibps_suite/
â”œâ”€â”€ ibps_api/
â”‚ â”œâ”€â”€ settings.py # Django project configuration
â”‚ â”œâ”€â”€ urls.py # URL routing for API
â”‚ â”œâ”€â”€ wsgi.py # WSGI entry point
â”‚ â””â”€â”€ ...
â”œâ”€â”€ ibps_jobs/
â”‚ â”œâ”€â”€ models.py # Job model definition
â”‚ â”œâ”€â”€ views.py # API views using DRF
â”‚ â”œâ”€â”€ serializers.py # Converts data to JSON
â”‚ â”œâ”€â”€ urls.py # Job-related API routes
â”‚ â””â”€â”€ ...
â”œâ”€â”€ scraper/
â”‚ â”œâ”€â”€ ibps_scraper.py # Scraping script for IBPS website
â”‚ â””â”€â”€ outputs/
â”‚ â””â”€â”€ ibps_jobs.json # JSON output file from scraper
â”œâ”€â”€ load_scraped_jobs.py # Script to load JSON data into Django DB
â””â”€â”€ db.sqlite3 # SQLite database

yaml
Copy code

---

## âš¡ How It Works (Step by Step)

### 1ï¸âƒ£ Scraping Data  
The **scraper script** (`ibps_scraper.py`) visits the official [IBPS website](https://www.ibps.in) and extracts job titles, links, and publish dates.  
It saves the scraped output into a JSON file (`ibps_jobs.json`) inside the `scraper/outputs` folder.

Example JSON:
json
[
  {
    "Job Title": "CRP Clerical cadre",
    "Location": "All India",
    "Publish Date": "N/A",
    "Link": "https://www.ibps.in/index.php/clerical-cadre"
  }
]
2ï¸âƒ£ Importing into Database
Once the data is scraped, it is loaded into the database using the load_scraped_jobs.py script:

bash
Copy code
python load_scraped_jobs.py
This reads the JSON and creates records in the Job model in Django.

3ï¸âƒ£ Exposing Data through API
The Django REST Framework exposes an authenticated API endpoint:

ruby
Copy code
GET http://127.0.0.1:8000/api/jobs/
Only users with a valid Token can access it.
The API returns a JSON response like this:

json
Copy code
[
  {
    "id": 1,
    "title": "CRP Clerical cadre",
    "link": "https://www.ibps.in/index.php/clerical-cadre",
    "posted_date": null
  }
]
ğŸ§± Django Model Example
python
Copy code
class Job(models.Model):
    title = models.CharField(max_length=255)
    link = models.URLField()
    posted_date = models.DateField(null=True, blank=True)

    def __str__(self):
        return self.title
ğŸ” Authentication Setup
The API uses Token Authentication:

Each user has a unique token.

You must send this token with your request headers.

Example using PowerShell or cURL:

bash
Copy code
curl -Method GET http://127.0.0.1:8000/api/jobs/ `
  -Headers @{ "Authorization" = "Token your_generated_token" }
ğŸ§° How to Run This Project Locally
1ï¸âƒ£ Clone the repository
bash
Copy code
git clone https://github.com/Sumit-kumar1-stack/IBPS-Job-Scraper-REST-API.git
cd IBPS-Job-Scraper-REST-API
2ï¸âƒ£ Create and activate virtual environment
bash
Copy code
python -m venv venv
venv\Scripts\activate
3ï¸âƒ£ Install dependencies
bash
Copy code
pip install -r requirements.txt
4ï¸âƒ£ Run database migrations
bash
Copy code
python manage.py makemigrations
python manage.py migrate
5ï¸âƒ£ Create a superuser
bash
Copy code
python manage.py createsuperuser
6ï¸âƒ£ Run the scraper and import jobs
bash
Copy code
python scraper/ibps_scraper.py
python load_scraped_jobs.py
7ï¸âƒ£ Start the Django server
bash
Copy code
python manage.py runserver
8ï¸âƒ£ Access API
Visit: http://127.0.0.1:8000/api/jobs/
Use your authentication token to view the job list.

ğŸ§  How to Explain in Interviews
â€œI built a Django REST API that scrapes real job postings from the official IBPS recruitment site.
It uses Pythonâ€™s BeautifulSoup to collect job data, saves it in JSON, then loads it into a Django database.
Using Django REST Framework, I created API endpoints to expose these job details securely with token authentication.
The project can easily be extended to scrape other government job portals as well by updating the scraper logic.â€

ğŸŒ Future Scope
Add automated daily scraping using CRON jobs.

Extend scraper for multiple government job websites.

Add a frontend dashboard using React or Streamlit.

Deploy on cloud (AWS, Render, or Vercel).

ğŸ‘¨â€ğŸ’» Author
Sumit Kumar
ğŸ“§ Email: your.email@example.com
ğŸ”— GitHub: https://github.com/Sumit-kumar1-stack

ğŸ Conclusion
This project demonstrates end-to-end automation â€” from web scraping to database management and REST API development.
Itâ€™s a great example of combining Python, Django, and REST principles to build scalable, real-world automation tools.

